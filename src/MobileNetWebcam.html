<!DOCTYPE html>
<html>

<head>

    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.0"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <style>
        #wrapper {
            text-align: center;
            margin: 10px auto;
        }

        #overlay {
            width: 550px;
        }

        #output_image {
            width: 550px;
        }
        .inline {
            display: inline-block;
        }
    </style>
</head>

<body>
    <center style="padding:10px; margin:5px">
        <h4>
            <span id="status">Model Loading ...</span>
        </h4>
    </center>
    <center style="padding:10px">
        <button type="button" id='start' class="btn btn-outline-primary" onclick='startVideo()'>Start Video</button>
    </center>
    <div class="inline">
        <center><span id="original_video"></span></center>
        <video id='video' width="500px"></video>
    </div>

    <div class="inline">
        <!--        <center><span id="emotion_video"></span></center>-->
        <canvas id="canvas" src="" style=" margin-top:10px;" />
    </div>
    <div id = "thank">
        <center style="padding:10px; margin:5px">
            <div>Maintained by <a href='http://mirlab.org/users/kevin.hsiao/'>Kevin Hsiao </a> and special thanks <a href="mailto:haochun.fu@mirlab.org" target="_top">Haochun Fu</a></div>
        </center>
    </div>
</body>
<script>
    // check using phone or not
    if (/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
        alert('Sorry, this website not support mobile divices currently.');
        history.back();
    }

    // check using chrome
    if (!window.chrome) {
        if (confirm('This website needs Chrome browser!!!')) {
            closewin();
        } else {
            history.back();
        }
    }

    var constraints = {
        video: true
    };

    var $body = document.querySelector('body');
    //    var status = document.getElementById('status');
    var emotion_labels = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"];
    var emotion_colors = ["#ff0000", "#00a800", "#ff4fc1", "#ffe100", "#306eff", "#ff9d00", "#7c7c7c"];
    var offset_x = 15;
    var offset_y = 40;

    loadModel('../models/mobilenetv1_models/model.json')
    // create model
    async function createModel(path) {
        let model_tmp = await tf.loadModel(path)
        return model_tmp
    }

    // load models
    async function loadModel(path) {
        var status = document.getElementById('status');
        //        status.innerText = "Model Loading ..."
        model = await createModel(path)

        status.innerText = "Model Loaded !!!"
    }


    function createVideoElement() {
        let $video = document.createElement('video')
        $video.style.maxWidth = '100vw'
        $video.style.width = '100vw'
        $video.style.maxHeight = '0vh'
        $body.appendChild($video)
        return $video
    }

    function handleError(error) {
        if (error.name === 'DevicesNotFoundError') {
            alert('No camera detected. <br> Do you have any camera connected?');
        } else if (error.name === 'NotAllowedError') {
            alert('You have to allow camera access in order to run this experiment.');
        } else if (navigator.userAgent.indexOf('Chrome') > -1) {
            alert('Error. <br> Enable experimental features on chrome://flags/#enable-experimental-web-platform-features');
        } else {
            alert('Error. <br> Does your browser supports FaceDetector API?');
        }
        console.error(error)
    }

    function createCanvas(video) {

        const canvas = document.getElementById('canvas')
        const videoCompStyle = window.getComputedStyle(video)
        canvas.width = videoCompStyle.width.replace('px', '')
        canvas.height = videoCompStyle.height.replace('px', '')
        //        canvas.style.display = 'none'
        document.querySelector('body').appendChild(canvas)

        return canvas
    }

    function createDrawFunction() {

        const faceDetector = new window.FaceDetector({
            maxDetectedFaces: 3
        })
        let isDetectingFaces = false
        let faces = []
        let hideTimeout

        return async function draw(canvas, video) {
            window.requestAnimationFrame(() => draw(canvas, video))
            const context = canvas.getContext('2d')
            const videoCompStyle = window.getComputedStyle(video)
            const videoWidth = videoCompStyle.width.replace('px', '')
            const videoHeight = videoCompStyle.height.replace('px', '')
            context.drawImage(video, 0, 0, videoWidth, videoHeight)
            //            context.clearRect(0, 0, canvas.width, canvas.height);
            //            clearTimeout(hideTimeout)
            if (faces.length) {

                //                let canvas = document.getElementById('canvas')
                let ctx = context;
                //                let scale = 1;

                ctx.lineWidth = 4;
                ctx.font = "20px Arial"
                ctx.fillText('Result', 0, 0);
                for (var i = 0; i < faces.length; i++) {
                    ctx.beginPath();
                    var item = faces[i].boundingBox;
                    //                    console.log(item)
                    let s_x = Math.floor(item.x - offset_x / 2);
                    let s_y = Math.floor(item.y - offset_y / 2);
                    let s_w = Math.floor(item.width + offset_x);
                    let s_h = Math.floor(item.height + offset_y);

                    let cT = ctx.getImageData(s_x, s_y, s_w, s_h);
                    cT = preprocess(cT);
                    z = model.predict(cT)

                    let index = z.argMax(1).dataSync()[0]
                    let label = emotion_labels[index];

                    ctx.strokeStyle = emotion_colors[index];
                    ctx.rect(s_x, s_y, s_w, s_h);
                    ctx.stroke();
                    ctx.fillStyle = emotion_colors[index];
                    ctx.fillText(label, s_x, s_y);
                    ctx.closePath();
                }
            } else {
                console.log('NO FACE')
                //                status.innerHTML = "NO FACE";
            }

            if (isDetectingFaces) {
                return
            }

            isDetectingFaces = true
            faces = await faceDetector.detect(canvas)
            isDetectingFaces = false
            var status = document.getElementById('status');
            status.innerHTML = "Running the model ... ";
        }
    }

    function preprocess(imgData) {
        return tf.tidy(() => {
            let tensor = tf.fromPixels(imgData).toFloat();

            tensor = tensor.resizeBilinear([64, 64])

            tensor = tf.cast(tensor, 'float32')
            const offset = tf.scalar(255.0);
            // Normalize the image 
            const normalized = tensor.div(offset);
            //We add a dimension to get a batch shape 
            const batched = normalized.expandDims(0)
            return batched
        })
    }


    function playCameraOnVideo(video) {
        return navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: 'user',
                    frameRate: 60
                },
                audio: false
            })
            .then(srcObject => video.srcObject = srcObject)
            .then(() => video.play())
    }

    async function main(video) {
        const video_canvas = createCanvas(video)
        const draw = createDrawFunction()
        draw(video_canvas, video)
    }

    function startVideo() {
        var x = document.getElementById("thank");
        x.style.display = "none";
        let elem = document.getElementById('start');
        elem.parentNode.removeChild(elem);
        var status = document.getElementById('status');
        status.innerHTML = "Initializing the camera ... ";

        var ori = document.getElementById("original_video");
        //        var emo = document.getElementById("emotion_video");
        ori.innerHTML = "Original: "
        //        emo.innerHTML = "Result : "
        playCameraOnVideo(video)
            .then(() => main(video))
            .catch(handleError)

    }
</script>

</html>